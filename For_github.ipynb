{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import the predictors (X), the response (y) from github\n",
    "X = pd.read_csv('https://raw.githubusercontent.com/mawalz05/Paper_Machine_Learning_and_Forecasting_Elections/master/X.csv')\n",
    "y = pd.read_csv(\"https://raw.githubusercontent.com/mawalz05/Paper_Machine_Learning_and_Forecasting_Elections/master/y.csv\", header=None)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# create pipeline\n",
    "pipe = Pipeline([('regr', LinearRegression())])\n",
    "\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "search_space = [{'regr': [LinearRegression()]},\n",
    "                {'regr': [Lasso(max_iter = 1000, normalize = True)],\n",
    "                 'regr__alpha': [1e-3,1e-2, 1, 5, 10, 20]},\n",
    "                {'regr': [Ridge(normalize = True)],\n",
    "                'regr__alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]},\n",
    "                {\"regr\": [ElasticNet(normalize = True, max_iter = 10000)],\n",
    "                 \"regr__alpha\":[1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20],\n",
    "                 \"regr__l1_ratio\": np.arange(0.0, 1.1,0.1)},\n",
    "                {\"regr\": [RandomForestRegressor()],\n",
    "                \"regr__n_estimators\": [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "                \"regr__max_features\": ['auto', 'sqrt'],\n",
    "                \"regr__max_depth\": [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                \"regr__min_samples_split\": [2, 5, 10],\n",
    "                \"regr__min_samples_leaf\": [1, 2, 4],\n",
    "                \"regr__bootstrap\": [True, False]},\n",
    "                {\"regr\": [GradientBoostingRegressor()],\n",
    "                \"regr__learning_rate\": [0.01, .05, .1, .5, 1],\n",
    "                \"regr__n_estimators\": [1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
    "                \"regr__max_depth\": np.linspace(1, 32, 32, endpoint=True),\n",
    "                \"regr__min_samples_split\": np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "                \"regr__min_samples_leaf\": np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "                \"regr__max_features\": list(range(1,X_train.shape[1]))},\n",
    "               {'regr': [SVR()],\n",
    "                'regr__kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "                'regr__C' : [1,5,10, 50, 100],\n",
    "                'regr__degree' : [2,3,4,5,6,7,8],\n",
    "                'regr__gamma' :np.logspace(-3,3, num=6, endpoint = False)},\n",
    "               {\"regr\": [MLPRegressor(max_iter = 10000)],\n",
    "                \"regr__hidden_layer_sizes\": [1,3,5,10, 15,30,100], \n",
    "                \"regr__activation\": [\"logistic\", \"tanh\", \"relu\"], \n",
    "                \"regr__solver\": [\"lbfgs\", \"sgd\", \"adam\"], \n",
    "                \"regr__alpha\": [float(x) for x in np.linspace(.0000001, .01, num = 10)]}]\n",
    "                \n",
    "# Creating a random search through parameters \n",
    "randomsearch = RandomizedSearchCV(pipe, search_space, n_iter = 1000, cv = 5, verbose =0, n_jobs = -1)\n",
    "\n",
    "# Recoding the start time of the cell\n",
    "start_run = time.time()\n",
    "local_time = time.ctime(start_run)\n",
    "print('start time run: {}'.format(local_time))\n",
    "\n",
    "\n",
    "# Fit grid search and select the best models for the total results\n",
    "best_model = randomsearch.fit(X_train, y_train)\n",
    "model = best_model.best_estimator_.get_params()[\"regr\"]\n",
    "print(\"The best Model and parameters:\")\n",
    "# View best model\n",
    "print(best_model.best_estimator_.get_params()[\"regr\"])\n",
    "\n",
    "end_run1 = time.time()\n",
    "local_time = time.ctime(end_run1)\n",
    "print('end time: {} '.format(local_time))\n",
    "duration_run = round((end_run1 - start_run)/60, 2)\n",
    "print('Run 1 run time: {}'.format(duration_run))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model object by fitting the data on the best parameters\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Using 5-fold cross validation to get the RMSE\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring = 'neg_root_mean_squared_error', n_jobs = -1)\n",
    "print(scores)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictions for the training and testing sets\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Caclulating the RMSE for the training and testing sets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_test = sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse_train = sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(rmse_test)\n",
    "print(rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning y_test into an array anf dinding the sahpe\n",
    "y_test = np.array(y_test)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an array to calculate the testing accuracy.\n",
    "y_test = y_test.reshape(180, 1) #reshaping the data to be the length of the test set X 1\n",
    "y_pred = y_pred.reshape(180, 1) #reshaping the data to be the length of the prediction array X 1\n",
    "results = np.concatenate((y_test, y_pred), axis = 1) #Combinng the two arrays [[Y,Y_hat],[Y,Y_hat],...]\n",
    "\n",
    "#Add 1 for every instance where both the prediction and training response variable are either above or below 50 percent\n",
    "results2 = 0\n",
    "for i in range(180):\n",
    "    if results[i][0] > 50 and results[i][1] > 50:\n",
    "        results2 += 1\n",
    "    elif results[i][0] < 50 and results[i][1] < 50:\n",
    "        results2 += 1\n",
    "    else:\n",
    "        results2 += 0\n",
    "\n",
    "#Calculaing the testing accuray\n",
    "print(\"The testing accuracy is: \" + str(results2/len(results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
